---
title: "Garbage Can Regression Challenge"
format:
  html: default
execute:
  echo: false
  eval: true
---

```{python}
#| echo: false
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import statsmodels.api as sm
from statsmodels.stats.outliers_influence import variance_inflation_factor

# Data with known true relationships: Anxiety = Stress + 0.1 √ó Time
data = {
    'Stress': [0,0,0,1,1,1,2,2,2,8,8,8,12,12,12],
    'StressSurvey': [0,0,0,3,3,3,6,6,6,9,9,9,12,12,12],
    'Time': [0,1,1,1,1,1,2,2,2,2,2,2.1,2.2,2.2,2.2],
    'Anxiety': [0,0.1,0.1,1.1,1.1,1.1,2.2,2.2,2.2,8.2,8.2,8.21,12.22,12.22,12.22]
}

observDF = pd.DataFrame(data)
print(observDF)
```

### Regression of Anxiety on Stress Survey

```{python}
#| echo: false
# Fit the bivariate regression model
X1 = observDF[['StressSurvey']]
y = observDF['Anxiety']

# Using statsmodels for detailed output
X1_sm = sm.add_constant(X1)
model1 = sm.OLS(y, X1_sm).fit()

# Display the regression results
print(model1.summary())
```


### Estimated Coefficients

```{python}
#| echo: false
# Print the estimated coefficients
intercept = model1.params['const']
stress_coef = model1.params['StressSurvey']

print("Estimated Coefficients:")
print(f"Intercept (Œ≤‚ÇÄ): {intercept:.4f}")
print(f"StressSurvey (Œ≤‚ÇÅ): {stress_coef:.4f}")
print(f"\nRegression Equation: Anxiety = {intercept:.4f} + {stress_coef:.4f} √ó StressSurvey")
```

---

**INTERPRETATION:**

The regression using StressSurvey produces the equation Anxiety = ‚Äì1.52 + 1.05 √ó StressSurvey. This means that when StressSurvey increases by one unit, Anxiety is predicted to rise by about 1.05 units. The intercept of ‚Äì1.52 implies that if StressSurvey were zero, Anxiety would be negative, which is not realistic but reflects how the line was forced to fit the data. Compared to the true relationship, which is Anxiety = Stress + 0.1 √ó Time, the slope is too high. If StressSurvey were simply three times Stress as it appears in the data table, the slope should be closer to 0.33, not 1.05. The reason for the inflation is that the model leaves out Time, which is correlated with StressSurvey, so the regression mistakenly shifts part of Time‚Äôs effect onto StressSurvey. The result is a model that fits well on paper but does not reflect the true underlying process.



### Scatter Plot Analysis and Commentary

```{python}
#| echo: false
import matplotlib.pyplot as plt
from scipy import stats

# Create a detailed scatter plot with additional analysis
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

# Plot 1: Original scatter plot with regression line
ax1.scatter(observDF['StressSurvey'], observDF['Anxiety'], color='blue', s=80, alpha=0.7)
ax1.plot(observDF['StressSurvey'], model1.fittedvalues, color='red', linewidth=2, label='Regression Line')

# Add confidence interval
newx = np.linspace(observDF['StressSurvey'].min(), observDF['StressSurvey'].max(), 100)
newx_df = pd.DataFrame({'const': 1, 'StressSurvey': newx})
pred = model1.get_prediction(newx_df)
pred_summary = pred.summary_frame(alpha=0.05)
ax1.plot(newx, pred_summary['mean_ci_lower'], 'r--', linewidth=1, label='95% CI')
ax1.plot(newx, pred_summary['mean_ci_upper'], 'r--', linewidth=1)
ax1.set_xlabel('Stress Survey')
ax1.set_ylabel('Anxiety')
ax1.set_title('Anxiety vs Stress Survey\nwith Regression Line')
ax1.legend()
ax1.grid(True, alpha=0.3)

# Plot 2: Residuals plot to check assumptions
residuals = model1.resid
ax2.scatter(observDF['StressSurvey'], residuals, color='darkgreen', s=80, alpha=0.7)
ax2.axhline(y=0, color='red', linewidth=2)
ax2.set_xlabel('Stress Survey')
ax2.set_ylabel('Residuals')
ax2.set_title('Residuals vs Stress Survey\n(Checking Linearity)')
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# Save the main scatter plot
fig2, ax = plt.subplots(figsize=(8, 6))
ax.scatter(observDF['StressSurvey'], observDF['Anxiety'], color='blue', s=80, alpha=0.7)
ax.plot(observDF['StressSurvey'], model1.fittedvalues, color='red', linewidth=2)
ax.plot(newx, pred_summary['mean_ci_lower'], 'r--', linewidth=1)
ax.plot(newx, pred_summary['mean_ci_upper'], 'r--', linewidth=1)
ax.set_xlabel('Stress Survey')
ax.set_ylabel('Anxiety')
ax.set_title('Bivariate Regression: Anxiety vs Stress Survey')
ax.grid(True, alpha=0.3)
plt.savefig('anxiety_stress_regression.png', dpi=100, bbox_inches='tight')
plt.close()
```

### Fit Assessment and Commentary

```{python}
#| echo: false
# Detailed analysis of the regression fit
print("REGRESSION FIT ANALYSIS:")
print("========================\n")

# R-squared and adjusted R-squared
r_squared = model1.rsquared
adj_r_squared = model1.rsquared_adj

print("1. GOODNESS OF FIT:")
print(f"   R-squared: {r_squared:.4f} ({r_squared*100:.1f}% of variance explained)")
print(f"   Adjusted R-squared: {adj_r_squared:.4f}")

if r_squared > 0.8:
    print("   ‚úì Excellent fit - model explains most of the variance")
elif r_squared > 0.6:
    print("   ‚úì Good fit - model explains substantial variance")
elif r_squared > 0.4:
    print("   ‚ö† Moderate fit - model explains some variance")
else:
    print("   ‚ö† Poor fit - model explains little variance")

# Statistical significance
f_stat = model1.fvalue
f_pvalue = model1.f_pvalue

print("\n2. STATISTICAL SIGNIFICANCE:")
print(f"   F-statistic: {f_stat:.4f}")
print(f"   p-value: {f_pvalue:.6f}")

if f_pvalue < 0.001:
    print("   ‚úì Highly significant relationship (p < 0.001)")
elif f_pvalue < 0.01:
    print("   ‚úì Very significant relationship (p < 0.01)")
elif f_pvalue < 0.05:
    print("   ‚úì Significant relationship (p < 0.05)")
else:
    print("   ‚ö† Relationship not statistically significant (p ‚â• 0.05)")

# Coefficient significance
coef_pvalue = model1.pvalues['StressSurvey']
print("\n3. COEFFICIENT SIGNIFICANCE:")
print(f"   StressSurvey coefficient p-value: {coef_pvalue:.6f}")

if coef_pvalue < 0.05:
    print("   ‚úì StressSurvey coefficient is statistically significant")
else:
    print("   ‚ö† StressSurvey coefficient is not statistically significant")

# Potential issues
print("\n4. POTENTIAL ISSUES:")
print("   ‚Ä¢ Omitted variable bias: Time variable is missing from the model")
print("   ‚Ä¢ Variable scaling: Using StressSurvey instead of true Stress variable")
print(f"   ‚Ä¢ Small sample size: Only {len(observDF)} observations")
print("   ‚Ä¢ Perfect linear relationship: Data appears artificially generated")

# Residual analysis
residuals = model1.resid
print("\n5. RESIDUAL ANALYSIS:")
print(f"   Mean of residuals: {residuals.mean():.6f} (should be ~0)")
print(f"   Standard deviation of residuals: {residuals.std():.4f}")

# Check for patterns in residuals
if abs(residuals.mean()) < 0.001:
    print("   ‚úì Residuals centered around zero")
else:
    print("   ‚ö† Residuals not centered around zero")
```

---

**SCATTER PLOT INTERPRETATION:**

The scatter plot shows a strong linear relationship between StressSurvey and Anxiety with a high R^2 value. Most of the observations fall inside the confidence bands, and the residuals are centered around zero, so the linear model looks like a good match for the data. At first glance, this suggests that StressSurvey is an excellent predictor of Anxiety.

However, upon further examination there are some potential issues. The model leaves out Time, which is part of the true equation for Anxiety, so the StressSurvey coefficient is absorbing some of Time's effect. StressSurvey itself is only a proxy for the real Stress measure, and it doesn't scale perfectly, which means the slope may not represent the true relationship. Even though the R¬≤ value is very high, that alone doesn't prove the coefficients are correct.

---

## Question 3: Bivariate Regression of Anxiety on Time

### Regression of Anxiety on Time

```{python}
#| echo: false
# Fit the bivariate regression model: Anxiety ~ Time
X2 = observDF[['Time']]
X2_sm = sm.add_constant(X2)
model2 = sm.OLS(y, X2_sm).fit()

# Display the regression results
print(model2.summary())
```

### Estimated Coefficients for Time Model

```{python}
#| echo: false
# Print the estimated coefficients for the Time model
intercept_time = model2.params['const']
time_coef = model2.params['Time']

print("Estimated Coefficients (Anxiety ~ Time):")
print("======================================")
print(f"Intercept (Œ≤‚ÇÄ): {intercept_time:.4f}")
print(f"Time (Œ≤‚ÇÅ): {time_coef:.4f}")
print(f"\nRegression Equation: Anxiety = {intercept_time:.4f} + {time_coef:.4f} √ó Time")
```

---

**INTERPRETATION:**

The regression using Time produces the equation Anxiety = ‚Äì3.68 + 5.34 √ó Time. This means that for each one-unit increase in Time, Anxiety is predicted to rise by about 5.34 units. The intercept of ‚Äì3.68 suggests that if Time were zero, Anxiety would be negative, which isn‚Äôt realistic but reflects how the line was adjusted to fit the data. Compared to the true relationship, which is Anxiety = Stress + 0.1 √ó Time, the slope is far too large. The true effect of Time is only 0.1, but because Stress and Time rise together in this dataset, the regression gives Time credit for Stress‚Äôs much stronger effect. This is a clear case of omitted variable bias: by leaving Stress out, the model inflates the Time coefficient. While the fit shows statistical significance, it tells the wrong story about what drives Anxiety. In practice, the model looks convincing but is misleading because it exaggerates Time‚Äôs role and ignores the real driver.

---

### Scatter Plot: Anxiety vs Time

```{python}
#| echo: false
# Create scatter plot for Anxiety vs Time
fig, ax = plt.subplots(figsize=(8, 6))
ax.scatter(observDF['Time'], observDF['Anxiety'], color='purple', s=80, alpha=0.7)
ax.plot(observDF['Time'], model2.fittedvalues, color='red', linewidth=2, label='Regression Line')

# Add confidence interval
newx_time = np.linspace(observDF['Time'].min(), observDF['Time'].max(), 100)
newx_time_df = pd.DataFrame({'const': 1, 'Time': newx_time})
pred_time = model2.get_prediction(newx_time_df)
pred_time_summary = pred_time.summary_frame(alpha=0.05)
ax.plot(newx_time, pred_time_summary['mean_ci_lower'], 'r--', linewidth=1, label='95% CI')
ax.plot(newx_time, pred_time_summary['mean_ci_upper'], 'r--', linewidth=1)
ax.set_xlabel('Time')
ax.set_ylabel('Anxiety')
ax.set_title('Anxiety vs Time\nwith Regression Line')
ax.legend()
ax.grid(True, alpha=0.3)
plt.tight_layout()
plt.show()

# Save the plot
fig2, ax2 = plt.subplots(figsize=(8, 6))
ax2.scatter(observDF['Time'], observDF['Anxiety'], color='purple', s=80, alpha=0.7)
ax2.plot(observDF['Time'], model2.fittedvalues, color='red', linewidth=2)
ax2.plot(newx_time, pred_time_summary['mean_ci_lower'], 'r--', linewidth=1)
ax2.plot(newx_time, pred_time_summary['mean_ci_upper'], 'r--', linewidth=1)
ax2.set_xlabel('Time')
ax2.set_ylabel('Anxiety')
ax2.set_title('Bivariate Regression: Anxiety vs Time')
ax2.grid(True, alpha=0.3)
plt.savefig('anxiety_time_regression.png', dpi=100, bbox_inches='tight')
plt.close()
```

### Time Model Fit Assessment and Commentary

```{python}
#| echo: false
# Detailed analysis of the Time regression fit
print("TIME MODEL FIT ANALYSIS:")
print("========================\n")

# R-squared and adjusted R-squared
r_squared_time = model2.rsquared
adj_r_squared_time = model2.rsquared_adj

print("1. GOODNESS OF FIT:")
print(f"   R-squared: {r_squared_time:.4f} ({r_squared_time*100:.1f}% of variance explained)")
print(f"   Adjusted R-squared: {adj_r_squared_time:.4f}")

if r_squared_time > 0.8:
    print("   ‚úì Excellent fit - model explains most of the variance")
elif r_squared_time > 0.6:
    print("   ‚úì Good fit - model explains substantial variance")
elif r_squared_time > 0.4:
    print("   ‚ö† Moderate fit - model explains some variance")
else:
    print("   ‚ö† Poor fit - model explains little variance")

# Statistical significance
f_stat_time = model2.fvalue
f_pvalue_time = model2.f_pvalue

print("\n2. STATISTICAL SIGNIFICANCE:")
print(f"   F-statistic: {f_stat_time:.4f}")
print(f"   p-value: {f_pvalue_time:.6f}")

if f_pvalue_time < 0.001:
    print("   ‚úì Highly significant relationship (p < 0.001)")
elif f_pvalue_time < 0.01:
    print("   ‚úì Very significant relationship (p < 0.01)")
elif f_pvalue_time < 0.05:
    print("   ‚úì Significant relationship (p < 0.05)")
else:
    print("   ‚ö† Relationship not statistically significant (p ‚â• 0.05)")

# Coefficient significance
coef_pvalue_time = model2.pvalues['Time']
print("\n3. COEFFICIENT SIGNIFICANCE:")
print(f"   Time coefficient p-value: {coef_pvalue_time:.6f}")

if coef_pvalue_time < 0.05:
    print("   ‚úì Time coefficient is statistically significant")
else:
    print("   ‚ö† Time coefficient is not statistically significant")

# Compare with StressSurvey model
print("\n4. COMPARISON WITH STRESS SURVEY MODEL:")
print(f"   StressSurvey model R-squared: {r_squared:.4f}")
print(f"   Time model R-squared: {r_squared_time:.4f}")

if r_squared > r_squared_time:
    print("   ‚Üí StressSurvey explains more variance than Time alone")
else:
    print("   ‚Üí Time explains more variance than StressSurvey alone")

# Potential issues
print("\n5. POTENTIAL ISSUES:")
print("   ‚Ä¢ OMITTED VARIABLE BIAS: Major issue - Stress variable is missing")
print("   ‚Ä¢ True relationship: Anxiety = Stress + 0.1 √ó Time")
print("   ‚Ä¢ This model only uses Time, ignoring the dominant Stress effect")
print("   ‚Ä¢ Time coefficient may be biased due to correlation with omitted Stress")
print(f"   ‚Ä¢ Small sample size: Only {len(observDF)} observations")
print(f"   ‚Ä¢ Limited Time variation: Time values range from {observDF['Time'].min():.1f} to {observDF['Time'].max():.1f}")

# Residual analysis
residuals_time = model2.resid
print("\n6. RESIDUAL ANALYSIS:")
print(f"   Mean of residuals: {residuals_time.mean():.6f} (should be ~0)")
print(f"   Standard deviation of residuals: {residuals_time.std():.4f}")

# Check for patterns in residuals
if abs(residuals_time.mean()) < 0.001:
    print("   ‚úì Residuals centered around zero")
else:
    print("   ‚ö† Residuals not centered around zero")

# True vs estimated coefficient comparison
print("\n7. COEFFICIENT ACCURACY:")
print(f"   True Time coefficient: 0.1")
print(f"   Estimated Time coefficient: {time_coef:.4f}")
print(f"   Bias: {time_coef - 0.1:.4f}")

if abs(time_coef - 0.1) < 0.01:
    print("   ‚úì Coefficient estimate is very close to true value")
elif abs(time_coef - 0.1) < 0.05:
    print("   ‚ö† Coefficient estimate is somewhat biased")
else:
    print("   ‚ö† Coefficient estimate is significantly biased")
```

---

**SCATTER PLOT INTERPRETATION:**

The scatter plot shows a strong linear relationship between Time and Anxiety with a high R^2 value. Most of the observations fall inside the confidence bands, and the residuals are centered around zero, so the linear model looks like a good match for the data. At first glance, this suggests that Time is an excellent predictor of Anxiety.

However, upon further examination there are some potential issues. The model leaves out Stress, which is part of the true equation for Anxiety, so the Time coefficient is absorbing some of Stress's effect. Time itself is only a proxy for the real Stress measure, and it doesn't scale perfectly, which means the slope may not represent the true relationship. Even though the R¬≤ value is very high, that alone doesn't prove the coefficients are correct.

Overall, the model looks convincing but is misleading because it exaggerates Time's role and ignores the real driver.

---

## Question 5: Multiple Regression of Anxiety on StressSurvey and Time

---

**üìù YOUR INTERPRETATION GOES HERE:**

*Write your interpretation of the multiple regression analysis here. Consider:*
- *How do the coefficients change when both variables are included?*
- *Does the R-squared improve compared to the single-variable models?*
- *Are both coefficients statistically significant?*
- *How close are the coefficients to the expected values?*

---

### Multiple Regression Model

```{python}
#| echo: false
# Fit the multiple regression model: Anxiety ~ StressSurvey + Time
X3 = observDF[['StressSurvey', 'Time']]
X3_sm = sm.add_constant(X3)
model3 = sm.OLS(y, X3_sm).fit()

# Display the regression results
print(model3.summary())
```

### Estimated Coefficients for Multiple Regression

```{python}
#| echo: false
# Print the estimated coefficients for the multiple regression model
intercept_mult = model3.params['const']
stress_coef_mult = model3.params['StressSurvey']
time_coef_mult = model3.params['Time']

print("Estimated Coefficients (Anxiety ~ StressSurvey + Time):")
print("=====================================================")
print(f"Intercept (Œ≤‚ÇÄ): {intercept_mult:.4f}")
print(f"StressSurvey (Œ≤‚ÇÅ): {stress_coef_mult:.4f}")
print(f"Time (Œ≤‚ÇÇ): {time_coef_mult:.4f}")
print(f"\nRegression Equation: Anxiety = {intercept_mult:.4f} + {stress_coef_mult:.4f} √ó StressSurvey + {time_coef_mult:.4f} √ó Time")
```

### Comparison with True Relationship

```{python}
#| echo: false
# Compare estimated coefficients with true relationship
print("COMPARISON: Estimated vs True Relationships (Multiple Regression)")
print("================================================================")
print("True generating equation: Anxiety = Stress + 0.1 √ó Time")
print(f"Estimated equation: Anxiety = {intercept_mult:.4f} + {stress_coef_mult:.4f} √ó StressSurvey + {time_coef_mult:.4f} √ó Time\n")

# True coefficients (remember StressSurvey = 3 √ó Stress)
true_intercept_multiple = 0  # In true model: Anxiety = Stress + 0.1 √ó Time (no intercept)
true_slope_stress_multiple = 1  # True coefficient for Stress
true_slope_time_multiple = 0.1  # True coefficient for Time
expected_stresssurvey_coef = 1/3  # Since StressSurvey = 3 √ó Stress

print("Coefficient Analysis:")
print("--------------------")
print("Intercept:")
print(f"  True (in generating model): 0")
print(f"  Estimated: {intercept_mult:.4f}")
print(f"  Difference: {intercept_mult - 0:.4f}\n")

print("StressSurvey coefficient:")
print(f"  Expected (1/3 of true Stress coefficient): {expected_stresssurvey_coef:.4f}")
print(f"  Estimated: {stress_coef_mult:.4f}")
print(f"  Difference from expected: {stress_coef_mult - expected_stresssurvey_coef:.4f}\n")

print("Time coefficient:")
print(f"  True: 0.1")
print(f"  Estimated: {time_coef_mult:.4f}")
print(f"  Difference: {time_coef_mult - 0.1:.4f}\n")

# Model fit comparison
r_squared_multiple = model3.rsquared
print("Model Fit:")
print(f"  R-squared: {r_squared_multiple:.4f} ({r_squared_multiple*100:.1f}% of variance explained)")

# Compare with single variable models
print("\nModel Comparison:")
print(f"  StressSurvey only R-squared: {r_squared:.4f}")
print(f"  Time only R-squared: {r_squared_time:.4f}")
print(f"  Multiple regression R-squared: {r_squared_multiple:.4f}")

if r_squared_multiple > max(r_squared, r_squared_time):
    print("  ‚úì Multiple regression explains more variance than either single variable model")
else:
    print("  ‚ö† Multiple regression does not improve over single variable models")
```

### Multiple Regression Fit Assessment

```{python}
#| echo: false
# Detailed analysis of the multiple regression fit
print("MULTIPLE REGRESSION FIT ANALYSIS:")
print("================================\n")

# R-squared and adjusted R-squared
adj_r_squared_multiple = model3.rsquared_adj

print("1. GOODNESS OF FIT:")
print(f"   R-squared: {r_squared_multiple:.4f} ({r_squared_multiple*100:.1f}% of variance explained)")
print(f"   Adjusted R-squared: {adj_r_squared_multiple:.4f}")

if r_squared_multiple > 0.95:
    print("   ‚úì Excellent fit - model explains almost all variance")
elif r_squared_multiple > 0.8:
    print("   ‚úì Very good fit - model explains most of the variance")
elif r_squared_multiple > 0.6:
    print("   ‚úì Good fit - model explains substantial variance")
else:
    print("   ‚ö† Moderate fit - model explains some variance")

# Statistical significance
f_stat_multiple = model3.fvalue
f_pvalue_multiple = model3.f_pvalue

print("\n2. OVERALL MODEL SIGNIFICANCE:")
print(f"   F-statistic: {f_stat_multiple:.4f}")
print(f"   p-value: {f_pvalue_multiple:.6f}")

if f_pvalue_multiple < 0.001:
    print("   ‚úì Highly significant overall model (p < 0.001)")
elif f_pvalue_multiple < 0.01:
    print("   ‚úì Very significant overall model (p < 0.01)")
elif f_pvalue_multiple < 0.05:
    print("   ‚úì Significant overall model (p < 0.05)")
else:
    print("   ‚ö† Overall model not statistically significant (p ‚â• 0.05)")

# Individual coefficient significance
stress_pvalue_mult = model3.pvalues['StressSurvey']
time_pvalue_mult = model3.pvalues['Time']

print("\n3. INDIVIDUAL COEFFICIENT SIGNIFICANCE:")
print(f"   StressSurvey coefficient p-value: {stress_pvalue_mult:.6f}")
print(f"   Time coefficient p-value: {time_pvalue_mult:.6f}")

if stress_pvalue_mult < 0.05:
    print("   ‚úì StressSurvey coefficient is statistically significant")
else:
    print("   ‚ö† StressSurvey coefficient is not statistically significant")

if time_pvalue_mult < 0.05:
    print("   ‚úì Time coefficient is statistically significant")
else:
    print("   ‚ö† Time coefficient is not statistically significant")

# Coefficient accuracy assessment
print("\n4. COEFFICIENT ACCURACY:")
stress_bias = stress_coef_mult - expected_stresssurvey_coef
time_bias = time_coef_mult - 0.1

print(f"   StressSurvey coefficient bias: {stress_bias:.4f}")
print(f"   Time coefficient bias: {time_bias:.4f}")

if abs(stress_bias) < 0.01 and abs(time_bias) < 0.01:
    print("   ‚úì Both coefficients are very close to expected values")
elif abs(stress_bias) < 0.05 and abs(time_bias) < 0.05:
    print("   ‚úì Both coefficients are reasonably close to expected values")
else:
    print("   ‚ö† Some coefficients show significant bias")

# Key insights
print("\n5. KEY INSIGHTS:")
print("   ‚Ä¢ This model includes both variables from the true relationship")
print("   ‚Ä¢ StressSurvey captures the main Stress effect (scaled by 1/3)")
print("   ‚Ä¢ Time coefficient should be close to the true 0.1 value")
print("   ‚Ä¢ This is the most complete model given the available variables")
```

---

**üìù YOUR INTERPRETATION - Question 5:**

*Based on the multiple regression analysis (StressSurvey + Time), write your interpretation:*
- *How does including both variables improve the model?*
- *Which variable (StressSurvey or Time) has a larger effect on Anxiety?*
- *Are the coefficients close to the expected values (StressSurvey ‚âà 0.333, Time ‚âà 0.1)?*
- *What does the high R-squared tell you about the model fit?*
- *Why is this model better than the single-variable models?*

---

## Multiple Regression of Anxiety on Stress and Time

---

**üìù YOUR INTERPRETATION GOES HERE:**

*Write your interpretation of the Stress + Time regression analysis here. Consider:*
- *This model uses the TRUE variables from the data generation process*
- *How close are the estimated coefficients to the true values (Stress = 1.0, Time = 0.1)?*
- *Why is this model expected to perform better than using StressSurvey?*

---

### Multiple Regression Model (Using Actual Stress)

```{python}
#| echo: false
# Fit the multiple regression model: Anxiety ~ Stress + Time
X4 = observDF[['Stress', 'Time']]
X4_sm = sm.add_constant(X4)
model4 = sm.OLS(y, X4_sm).fit()

# Display the regression results
print(model4.summary())
```

### Estimated Coefficients (Stress + Time Model)

```{python}
#| echo: false
# Print the estimated coefficients for Stress + Time model
intercept_stress = model4.params['const']
stress_coef_true = model4.params['Stress']
time_coef_stress = model4.params['Time']

print("Estimated Coefficients (Anxiety ~ Stress + Time):")
print("================================================")
print(f"Intercept (Œ≤‚ÇÄ): {intercept_stress:.4f}")
print(f"Stress (Œ≤‚ÇÅ): {stress_coef_true:.4f}")
print(f"Time (Œ≤‚ÇÇ): {time_coef_stress:.4f}")
print(f"\nRegression Equation: Anxiety = {intercept_stress:.4f} + {stress_coef_true:.4f} √ó Stress + {time_coef_stress:.4f} √ó Time")
```

### Comparison with True Relationship (Perfect Match Expected!)

```{python}
#| echo: false
# Compare with true relationship - this should be nearly perfect!
print("COMPARISON: Estimated vs True Relationships (Stress + Time Model)")
print("================================================================")
print("True generating equation: Anxiety = Stress + 0.1 √ó Time")
print(f"Estimated equation: Anxiety = {intercept_stress:.4f} + {stress_coef_true:.4f} √ó Stress + {time_coef_stress:.4f} √ó Time\n")

# True coefficients
true_intercept_actual = 0
true_stress_coef = 1.0
true_time_coef = 0.1

print("Coefficient Analysis:")
print("--------------------")
print("Intercept:")
print(f"  True: 0")
print(f"  Estimated: {intercept_stress:.4f}")
print(f"  Difference: {intercept_stress - 0:.4f}")
print(f"  Error: {abs(intercept_stress - 0):.6f}\n")

print("Stress coefficient:")
print(f"  True: 1.0")
print(f"  Estimated: {stress_coef_true:.4f}")
print(f"  Difference: {stress_coef_true - 1.0:.4f}")
print(f"  Error: {abs(stress_coef_true - 1.0):.6f}\n")

print("Time coefficient:")
print(f"  True: 0.1")
print(f"  Estimated: {time_coef_stress:.4f}")
print(f"  Difference: {time_coef_stress - 0.1:.4f}")
print(f"  Error: {abs(time_coef_stress - 0.1):.6f}\n")

# Model fit
r_squared_stress_time = model4.rsquared
adj_r_squared_stress_time = model4.rsquared_adj

print("Model Fit:")
print(f"  R-squared: {r_squared_stress_time:.4f} ({r_squared_stress_time*100:.1f}% of variance explained)")
print(f"  Adjusted R-squared: {adj_r_squared_stress_time:.4f}")

print("\nKEY INSIGHT:")
print("This model uses the TRUE variables from the data generation process!")
print("The coefficients should be nearly identical to the true values:")
print(f"  Stress coefficient should be ‚âà 1.0 (actual: {stress_coef_true:.4f})")
print(f"  Time coefficient should be ‚âà 0.1 (actual: {time_coef_stress:.4f})")
print(f"  Intercept should be ‚âà 0.0 (actual: {intercept_stress:.4f})")
```

### Model Comparison: All Models Side-by-Side

```{python}
#| echo: false
# Compare all models
print("COMPREHENSIVE MODEL COMPARISON:")
print("=" * 70)
print("\nModel 1: Anxiety ~ StressSurvey")
print(f"  R-squared: {r_squared:.4f}")
print(f"  Coefficients: {intercept:.4f} + {stress_coef:.4f} √ó StressSurvey")

print("\nModel 2: Anxiety ~ Time")
print(f"  R-squared: {r_squared_time:.4f}")
print(f"  Coefficients: {intercept_time:.4f} + {time_coef:.4f} √ó Time")

print("\nModel 3: Anxiety ~ StressSurvey + Time")
print(f"  R-squared: {r_squared_multiple:.4f}")
print(f"  Coefficients: {intercept_mult:.4f} + {stress_coef_mult:.4f} √ó StressSurvey + {time_coef_mult:.4f} √ó Time")

print("\nModel 4: Anxiety ~ Stress + Time (TRUE MODEL)")
print(f"  R-squared: {r_squared_stress_time:.4f}")
print(f"  Coefficients: {intercept_stress:.4f} + {stress_coef_true:.4f} √ó Stress + {time_coef_stress:.4f} √ó Time")

print("\n" + "=" * 70)
print("BEST MODEL: Model 4 (Anxiety ~ Stress + Time)")
print("This model matches the true data generation process!")
print(f"It explains {r_squared_stress_time*100:.1f}% of the variance in Anxiety")
```

---

## Comparing the Two Multiple Regression Models

### R-squared Comparison

```{python}
#| echo: false
print("R-SQUARED COMPARISON:")
print("=" * 70)
print(f"\nModel 3 (Anxiety ~ StressSurvey + Time):")
print(f"  R-squared = {r_squared_multiple:.4f} ({r_squared_multiple*100:.1f}% of variance explained)")

print(f"\nModel 4 (Anxiety ~ Stress + Time):")
print(f"  R-squared = {r_squared_stress_time:.4f} ({r_squared_stress_time*100:.1f}% of variance explained)")

print(f"\nDifference: {abs(r_squared_stress_time - r_squared_multiple):.6f}")

if abs(r_squared_stress_time - r_squared_multiple) < 0.001:
    print("\nINTERPRETATION: The R-squared values are nearly identical between the two")
    print("models. This makes sense because StressSurvey is simply a scaled version")
    print("of Stress (StressSurvey = 3 √ó Stress). Both models capture the same")
    print("underlying relationship and explain virtually the same amount of variance")
    print("in Anxiety. Using the proxy variable (StressSurvey) instead of the actual")
    print("variable (Stress) does NOT reduce the model's explanatory power.")
else:
    print(f"\nINTERPRETATION: Model 4 has a {'higher' if r_squared_stress_time > r_squared_multiple else 'lower'} R-squared.")
    print("This suggests that using the actual Stress variable provides a better fit.")
```

### Coefficient Interpretation Comparison

```{python}
#| echo: false
print("\nCOEFFICIENT COMPARISON:")
print("=" * 70)

print("\nModel 3 (StressSurvey + Time):")
print(f"  Intercept: {intercept_mult:.4f}")
print(f"  StressSurvey coefficient: {stress_coef_mult:.4f} (expected ‚âà 0.333)")
print(f"  Time coefficient: {time_coef_mult:.4f} (expected ‚âà 0.1)")

print("\nModel 4 (Stress + Time):")
print(f"  Intercept: {intercept_stress:.4f}")
print(f"  Stress coefficient: {stress_coef_true:.4f} (expected = 1.0)")
print(f"  Time coefficient: {time_coef_stress:.4f} (expected = 0.1)")

print("\nTime Coefficient Comparison:")
print(f"  Model 3 Time coefficient: {time_coef_mult:.4f}")
print(f"  Model 4 Time coefficient: {time_coef_stress:.4f}")
print(f"  Difference: {abs(time_coef_mult - time_coef_stress):.6f}")

print("\nINTERPRETATION:")
print("The Time coefficients are nearly identical in both models, which is expected")
print("because Time is the same variable in both regressions. Model 4's coefficients")
print("are closer to the true values because it uses the actual Stress variable.")
print(f"The Stress coefficient ({stress_coef_true:.4f}) in Model 4 is very close to")
print(f"the true value of 1.0, while the StressSurvey coefficient ({stress_coef_mult:.4f})")
print(f"in Model 3 is close to 1/3 ‚âà 0.333, which is the expected scaling factor.")
```

### Statistical Significance Analysis

```{python}
#| echo: false
print("\nSTATISTICAL SIGNIFICANCE ANALYSIS:")
print("=" * 70)

# Model 3 significance
stress_pval_m3 = model3.pvalues['StressSurvey']
time_pval_m3 = model3.pvalues['Time']

print("\nModel 3 (StressSurvey + Time):")
print(f"  StressSurvey coefficient p-value: {stress_pval_m3:.6f}")
print(f"    {'‚úì Statistically significant (p < 0.05)' if stress_pval_m3 < 0.05 else '‚úó NOT statistically significant (p ‚â• 0.05)'}")
print(f"  Time coefficient p-value: {time_pval_m3:.6f}")
print(f"    {'‚úì Statistically significant (p < 0.05)' if time_pval_m3 < 0.05 else '‚úó NOT statistically significant (p ‚â• 0.05)'}")

both_sig_m3 = (stress_pval_m3 < 0.05) and (time_pval_m3 < 0.05)
print(f"\n  Both coefficients significant? {'YES ‚úì' if both_sig_m3 else 'NO ‚úó'}")

# Model 4 significance
stress_pval_m4 = model4.pvalues['Stress']
time_pval_m4 = model4.pvalues['Time']

print("\nModel 4 (Stress + Time):")
print(f"  Stress coefficient p-value: {stress_pval_m4:.6f}")
print(f"    {'‚úì Statistically significant (p < 0.05)' if stress_pval_m4 < 0.05 else '‚úó NOT statistically significant (p ‚â• 0.05)'}")
print(f"  Time coefficient p-value: {time_pval_m4:.6f}")
print(f"    {'‚úì Statistically significant (p < 0.05)' if time_pval_m4 < 0.05 else '‚úó NOT statistically significant (p ‚â• 0.05)'}")

both_sig_m4 = (stress_pval_m4 < 0.05) and (time_pval_m4 < 0.05)
print(f"\n  Both coefficients significant? {'YES ‚úì' if both_sig_m4 else 'NO ‚úó'}")

print("\n" + "=" * 70)
print("INTERPRETATION:")

if both_sig_m3 and both_sig_m4:
    print("\nBoth models show statistical significance in ALL coefficient estimates.")
    print("This indicates that both StressSurvey/Stress and Time contribute")
    print("significantly to explaining variation in Anxiety. The high significance")
    print("in both models demonstrates that:")
    print("  ‚Ä¢ The relationships are strong and reliable")
    print("  ‚Ä¢ We can be confident these variables matter for predicting Anxiety")
    print("  ‚Ä¢ The sample size, while small (n=15), is sufficient to detect these effects")
elif both_sig_m3 and not both_sig_m4:
    print("\nModel 3 shows significance in all coefficients, but Model 4 does not.")
    if time_pval_m4 >= 0.05:
        print("The Time coefficient in Model 4 is NOT significant. This could indicate")
        print("multicollinearity or that the small sample size limits precision.")
elif not both_sig_m3 and both_sig_m4:
    print("\nModel 4 shows significance in all coefficients, but Model 3 does not.")
    if time_pval_m3 >= 0.05:
        print("The Time coefficient in Model 3 is NOT significant, likely because")
        print("StressSurvey captures most of the variance, leaving little for Time.")
else:
    print("\nNeither model shows significance in all coefficients.")
    print("This suggests potential issues with multicollinearity or sample size.")
```

### Real-World Implications

```{python}
#| echo: false
print("\nREAL-WORLD IMPLICATIONS OF MULTIPLE REGRESSION:")
print("=" * 70)

print("\n1. VARIABLE SELECTION:")
print("   When using a proxy variable (StressSurvey) instead of the actual variable")
print("   (Stress), the model can still have excellent fit and statistical significance.")
print(f"   Both models have R-squared ‚âà {r_squared_multiple:.4f}, showing that proxy")
print("   variables can work well IF they have a consistent relationship with the")
print("   true variable. However, coefficient interpretation changes - you must")
print("   account for the scaling factor (3x in this case).")

print("\n2. MODEL SPECIFICATION:")
print("   Including both relevant variables (Stress/StressSurvey AND Time) is crucial.")
print(f"   The multiple regression R-squared ({r_squared_multiple:.4f}) is much higher")
print(f"   than the single-variable models (StressSurvey only: {r_squared:.4f},")
print(f"   Time only: {r_squared_time:.4f}). This demonstrates that omitting important")
print("   variables leads to biased coefficients and reduced explanatory power.")

print("\n3. STATISTICAL vs PRACTICAL SIGNIFICANCE:")
print("   A model can have high statistical significance but still use suboptimal")
print("   variables. Both models are highly significant, but Model 4 uses the TRUE")
print("   variables from the data generation process. In real research, you often")
print("   don't know the 'true' model, so you must:")
print("     ‚Ä¢ Use theory to guide variable selection")
print("     ‚Ä¢ Test alternative specifications")
print("     ‚Ä¢ Be cautious about causal interpretations")

print("\n4. RESEARCH PRACTICE IMPLICATIONS:")
print("   This exercise demonstrates several critical lessons:")
print("     ‚Ä¢ Omitted variable bias is real: Single-variable models gave biased")
print("       coefficient estimates")
print("     ‚Ä¢ Proxy variables can work: StressSurvey performed well despite not")
print("       being the 'true' variable")
print("     ‚Ä¢ Always check significance: Not all variables in a model may be")
print("       statistically significant")
print("     ‚Ä¢ R-squared isn't everything: Both multiple regression models had high")
print("       R-squared, but Model 4 better captures the true relationship")
print("     ‚Ä¢ Understanding the DGP matters: Knowing how data was generated helps")
print("       evaluate model quality - a luxury we don't have in real research!")
```

---

**üìù FINAL INTERPRETATION - Model Comparison:**

*Based on all four regression models, write your final interpretation:*
- *Which model performed best and why?*
- *How did Model 4 (Stress + Time) compare to Model 3 (StressSurvey + Time)?*
- *What did you learn about omitted variable bias from comparing these models?*
- *What did you learn about using proxy variables (StressSurvey vs Stress)?*
- *If you were advising a researcher, which model would you recommend and why?*

---
